# Бенчмарк локальных LLM для фронтенд-разработки

Набор задач для тестирования локальных LLM в контексте фронтенд-разработки (React, CSS, TypeScript).

## Тестируемые модели

| Модель | Параметры | Ключевые бенчмарки | Рекомендуемое железо |
|--------|-----------|-------------------|---------------------|
| [GLM-4.7-Flash](https://huggingface.co/zai-org/GLM-4.7-Flash) | 30B-A3B (MoE) | SWE-bench Verified, Terminal Bench 2 | GPU с поддержкой vLLM/SGLang |
| [RNJ-1](https://huggingface.co/EssentialAI/rnj-1) | 8B | SWE-bench 20.8%, HumanEval+ | MacBook M4 16GB |
| [Qwen3-4B-Thinking](https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507) | 4B | AIME 81.3%, HumanEval ~88% | 8-16GB RAM |

## Структура проекта

```
local_llm_benchmark/
├── tasks/                        # Описания задач по уровням
│   ├── level1_simple.md          # 3 задачи — базовые компоненты
│   ├── level2_medium.md          # 5 задач — типовая работа
│   ├── level3_hard.md            # 4 задачи — рефакторинг, оптимизация
│   ├── level4_impossible.md      # 2 задачи — границы применимости
│   └── level5_truly_impossible.md # 6 задач — критическое мышление
├── sandbox/                      # Файлы для каждой задачи
│   ├── task_1.1_button/
│   ├── ...
│   └── task_5.6_contradictions/
├── results/                      # Результаты тестирования моделей
│   └── rnj-1-instruct-mlx/      # Результаты RNJ-1
├── prompts/                      # Промпты для оценки
├── mini_config.yaml              # Конфигурация агента
└── run_mini.sh                   # Скрипт запуска бенчмарка
```

## Уровни сложности

### Уровень 1: Простые (все модели справятся)
- 1.1 Базовый React компонент Button
- 1.2 CSS Flexbox центрирование
- 1.3 Компонент Counter с useState

### Уровень 2: Средние
- 2.1 Кастомный хук useDebounce
- 2.2 CSS Grid Layout
- 2.3 Компонент UserCard с условным рендерингом
- 2.4 Форма с валидацией
- 2.5 CSS анимация spinner

### Уровень 3: Сложные
- 3.1 Рефакторинг компонента с багами
- 3.2 Оптимизация производительности списка
- 3.3 Архитектура системы валидации
- 3.4 Исправление бага по описанию

### Уровень 4: Экспертные
- 4.1 Сложный календарь бронирования
- 4.2 Миграция React Router v5 → v6

### Уровень 5: Действительно невозможные
- 5.1 Multi-file Bug Hunt — поиск бага через несколько файлов
- 5.2 API Reverse Engineering — вывод типов из примеров
- 5.3 Merge Conflict Resolution — разрешение конфликта с бизнес-логикой
- 5.4 Break the Code — написание тестов для поиска багов
- 5.5 Stateful Debug — отладка с последовательным выполнением команд
- 5.6 Contradictions — обнаружение противоречий в требованиях

## Методология оценки

Каждая задача оценивается по 6 критериям (макс. 10 баллов):

| Критерий | Баллы | Описание |
|----------|-------|----------|
| Компилируется | 0-1 | Код без синтаксических ошибок |
| Функциональность | 0-3 | Решает поставленную задачу |
| Качество кода | 0-2 | Читаемость, best practices |
| Edge cases | 0-2 | Обработка граничных случаев |
| TypeScript | 0-1 | Корректная типизация |
| Комментарии | 0-1 | Объяснение решения |

## Результаты

### RNJ-1 (8B) — Протестировано

| Уровень | Средний балл | Статус |
|---------|-------------|--------|
| Level 1 (Easy) | 10.0/10 ⭐ | Идеально |
| Level 2 (Medium) | 9.0/10 ⭐ | Отлично |
| Level 3 (Hard) | 7.25/10 | Хорошо |
| Level 4 (Expert) | 7.5/10 | Хорошо |
| Level 5 (Nightmare) | 6.17/10 | Провал |
| **Общий балл** | **7.80/10** | |

Подробные результаты: [results/rnj-1-instruct-mlx/result_all.md](results/rnj-1-instruct-mlx/result_all.md)

## Запуск

```bash
# Запуск одной задачи
./run_mini.sh task_1.1_button rnj-1-instruct-mlx

# Требуется запущенный LM Studio с нужной моделью на http://localhost:1234
```

## Формат тестирования

1. **Промпт** — стандартизированный для всех моделей
2. **Контекст** — одинаковый (если нужен код)
3. **Параметры** — temperature 0.7, max_tokens 4096
4. **Попытки** — 1 попытка на задачу (pass@1)

## Автор

Создано для доклада о локальных LLM в фронтенд-разработке.
